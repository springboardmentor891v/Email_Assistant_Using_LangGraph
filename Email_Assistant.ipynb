{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMpVdpQ1uW1TpKFBfsb/NY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor891v/Email_Assistant_Using_LangGraph/blob/manoj_preetham/Email_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yBPieKrd9xGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806a71d5-5c6d-448a-eaaa-fba0679016bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.6)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.188.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.12.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib) (2.43.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.1.7\n"
          ]
        }
      ],
      "source": [
        "pip install langgraph langchain langchain-openai google-auth-oauthlib google-api-python-client\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from typing import TypedDict, Annotated, List, Literal\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Google API Imports\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "uyDXcBLJUyaB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SETUP GMAIL AUTHENTICATION\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.modify']\n",
        "\n",
        "def get_gmail_service():\n",
        "    creds = None\n",
        "\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file(\n",
        "            'token.json', SCOPES\n",
        "        )\n",
        "\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credential.json',\n",
        "                SCOPES,\n",
        "                redirect_uri='urn:ietf:wg:oauth:2.0:oob'\n",
        "            )\n",
        "\n",
        "            auth_url, _ = flow.authorization_url(\n",
        "                prompt='consent'\n",
        "            )\n",
        "\n",
        "            print(\"\\nüîó OPEN THIS URL IN YOUR BROWSER:\\n\")\n",
        "            print(auth_url)\n",
        "\n",
        "            code = input(\"\\nüìå Paste the authorization code here: \")\n",
        "            flow.fetch_token(code=code)\n",
        "            creds = flow.credentials\n",
        "\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    return build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "service = get_gmail_service()"
      ],
      "metadata": {
        "id": "xTtqH5BYg82X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41a2cb0-7b1d-4dad-9872-e37300043d31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîó OPEN THIS URL IN YOUR BROWSER:\n",
            "\n",
            "https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=915502763627-c2ilmm6t0n042r0lbjg7mjr0f0mmqehn.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify&state=aTSwN2zKnqieGdJAU0C3P9BUgCGbJf&prompt=consent&access_type=offline\n",
            "\n",
            "üìå Paste the authorization code here: 4/1ASc3gC1ohtduKJo_f9UN_ok-wEI3_F83E5I3A1abxYDYVvzoVApbsqlhcfE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# =========================\n",
        "# OPENAI SETUP\n",
        "# =========================\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in Colab secrets\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def llm_call(prompt: str):\n",
        "    r = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return r.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "9VN5GJXbKHX1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Google Colab specific import for secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# Read API key from Colab secrets\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in Colab secrets. Please ensure it's set in the Colab 'Secrets' tab.\")\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "try:\n",
        "    # List models available for this key\n",
        "    models = client.models.list()\n",
        "\n",
        "    print(\"Models available for this key:\")\n",
        "    for model in models.data:\n",
        "        print(model.id)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "ybqszjDjNvA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1953764-ca9c-41fb-bce4-eac0c4314719"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models available for this key:\n",
            "gpt-3.5-turbo\n",
            "gpt-5.2-codex\n",
            "gpt-4o-mini-tts-2025-12-15\n",
            "gpt-realtime-mini-2025-12-15\n",
            "gpt-audio-mini-2025-12-15\n",
            "chatgpt-image-latest\n",
            "davinci-002\n",
            "babbage-002\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "dall-e-3\n",
            "dall-e-2\n",
            "gpt-3.5-turbo-1106\n",
            "tts-1-hd\n",
            "tts-1-1106\n",
            "tts-1-hd-1106\n",
            "text-embedding-3-small\n",
            "text-embedding-3-large\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4o-2024-08-06\n",
            "gpt-4o-audio-preview\n",
            "omni-moderation-latest\n",
            "omni-moderation-2024-09-26\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "o1-2024-12-17\n",
            "o1\n",
            "gpt-4o-mini-audio-preview\n",
            "o3-mini\n",
            "o3-mini-2025-01-31\n",
            "gpt-4o-2024-11-20\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-transcribe\n",
            "gpt-4o-mini-transcribe\n",
            "gpt-4o-mini-tts\n",
            "o3-2025-04-16\n",
            "o4-mini-2025-04-16\n",
            "o3\n",
            "o4-mini\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4.1\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-4.1-nano-2025-04-14\n",
            "gpt-4.1-nano\n",
            "gpt-image-1\n",
            "gpt-4o-audio-preview-2025-06-03\n",
            "gpt-4o-transcribe-diarize\n",
            "gpt-5-chat-latest\n",
            "gpt-5-2025-08-07\n",
            "gpt-5\n",
            "gpt-5-mini-2025-08-07\n",
            "gpt-5-mini\n",
            "gpt-5-nano-2025-08-07\n",
            "gpt-5-nano\n",
            "gpt-audio-2025-08-28\n",
            "gpt-realtime\n",
            "gpt-realtime-2025-08-28\n",
            "gpt-audio\n",
            "gpt-5-codex\n",
            "gpt-image-1-mini\n",
            "gpt-5-pro-2025-10-06\n",
            "gpt-5-pro\n",
            "gpt-audio-mini\n",
            "gpt-audio-mini-2025-10-06\n",
            "gpt-5-search-api\n",
            "gpt-realtime-mini\n",
            "gpt-realtime-mini-2025-10-06\n",
            "sora-2\n",
            "sora-2-pro\n",
            "gpt-5-search-api-2025-10-14\n",
            "gpt-5.1-chat-latest\n",
            "gpt-5.1-2025-11-13\n",
            "gpt-5.1\n",
            "gpt-5.1-codex\n",
            "gpt-5.1-codex-mini\n",
            "gpt-5.1-codex-max\n",
            "gpt-image-1.5\n",
            "gpt-5.2-2025-12-11\n",
            "gpt-5.2\n",
            "gpt-5.2-pro-2025-12-11\n",
            "gpt-5.2-pro\n",
            "gpt-5.2-chat-latest\n",
            "gpt-4o-mini-transcribe-2025-12-15\n",
            "gpt-4o-mini-transcribe-2025-03-20\n",
            "gpt-4o-mini-tts-2025-03-20\n",
            "whisper-1\n",
            "tts-1\n",
            "gpt-3.5-turbo-16k\n",
            "text-embedding-ada-002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# READ EMAIL\n",
        "# =========================\n",
        "def extract_email_data(service, msg_id):\n",
        "    message = service.users().messages().get(\n",
        "        userId='me',\n",
        "        id=msg_id,\n",
        "        format='full'\n",
        "    ).execute()\n",
        "\n",
        "    headers = message['payload']['headers']\n",
        "    subject = sender = date = \"\"\n",
        "\n",
        "    for h in headers:\n",
        "        if h['name'] == 'Subject':\n",
        "            subject = h['value']\n",
        "        elif h['name'] == 'From':\n",
        "            sender = h['value']\n",
        "        elif h['name'] == 'Date':\n",
        "            date = h['value']\n",
        "\n",
        "    body = \"\"\n",
        "    payload = message['payload']\n",
        "\n",
        "    if 'parts' in payload:\n",
        "        for part in payload['parts']:\n",
        "            if part['mimeType'] == 'text/plain':\n",
        "                data = part['body'].get('data')\n",
        "                if data:\n",
        "                    body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
        "    else:\n",
        "        data = payload['body'].get('data')\n",
        "        if data:\n",
        "            body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
        "\n",
        "    return subject, sender, date, body\n",
        "# =========================\n",
        "# FETCH UNREAD\n",
        "# =========================\n",
        "results = service.users().messages().list(\n",
        "    userId='me',\n",
        "    labelIds=['UNREAD'],\n",
        "    maxResults=100\n",
        ").execute()\n",
        "\n",
        "messages = results.get('messages', [])\n",
        "print(f\"üì¨ Unread emails found: {len(messages)}\")\n",
        "# =========================\n",
        "# PREVIEW (YOUR STYLE)\n",
        "# =========================\n",
        "emails = []\n",
        "for msg in messages:\n",
        "    msg_id = msg['id']\n",
        "    thread_id = msg['threadId']\n",
        "    subject, sender, date, body = extract_email_data(service, msg_id)\n",
        "\n",
        "    print(\"üìß SUBJECT:\", subject)\n",
        "    print(\"üë§ FROM:\", sender)\n",
        "    print(\"üìÖ DATE:\", date)\n",
        "    print(\"üìù BODY (preview):\", body[:300])\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    emails.append((msg_id, thread_id, subject, sender, body))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eni05kLNYQZO",
        "outputId": "6ea1b8dc-bed6-42f3-f629-4e2cb1d9c6cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¨ Unread emails found: 3\n",
            "üìß SUBJECT: Document verification\n",
            "üë§ FROM: Shane Gilbert S <shanegilbert1126@gmail.com>\n",
            "üìÖ DATE: Thu, 22 Jan 2026 09:08:30 +0530\n",
            "üìù BODY (preview): hey manoj,this is regarding document verification for your educational\r\n",
            "visa approval.Kindly do submit the required documents immediately.\r\n",
            "regards govt.\r\n",
            "\n",
            "------------------------------------------------------------\n",
            "üìß SUBJECT: Regarding intership\n",
            "üë§ FROM: Manoj Preetham v k <vkmanojpreetham2005@gmail.com>\n",
            "üìÖ DATE: Wed, 21 Jan 2026 23:06:05 +0530\n",
            "üìù BODY (preview): Hey applicant,\n",
            " You have been shortlisted thankyou\n",
            "\n",
            "------------------------------------------------------------\n",
            "üìß SUBJECT: hello iam Tony stark died as a hero and reborn as a villlian named victor von doom\n",
            "üë§ FROM: Harshith Y <hharshithy@gmail.com>\n",
            "üìÖ DATE: Wed, 21 Jan 2026 23:03:33 +0530\n",
            "üìù BODY (preview): \n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_email(subject, body):\n",
        "    prompt = f\"\"\"\n",
        "    Classify the following email into one of these categories: Emergency, Work, Promotion, Spam, Not-Useful, Personal.\n",
        "    Only return the category name and nothing else.\n",
        "\n",
        "    Email Subject: {subject}\n",
        "    Email Body: {body}\n",
        "    \"\"\"\n",
        "    category = llm_call(prompt)\n",
        "    # Ensure the category is one of the expected ones, default to 'Not-Useful' if not\n",
        "    valid_categories = [\"Emergency\", \"Work\", \"Promotion\", \"Spam\", \"Not-Useful\", \"Personal\"]\n",
        "    if category not in valid_categories:\n",
        "        # Try to infer if the LLM outputted something close, or default.\n",
        "        # This simple check can be improved with more robust parsing/correction.\n",
        "        for vc in valid_categories:\n",
        "            if vc.lower() in category.lower():\n",
        "                return vc\n",
        "        return \"Not-Useful\" # Fallback if classification is ambiguous or invalid\n",
        "    return category\n",
        "\n",
        "# =========================\n",
        "# UNREAD EMAIL SUMMARY\n",
        "# =========================\n",
        "\n",
        "# Fetch unread emails (keep your existing code if already present)\n",
        "results = service.users().messages().list(\n",
        "    userId='me',\n",
        "    labelIds=['UNREAD'],\n",
        "    maxResults=1000\n",
        ").execute()\n",
        "\n",
        "messages = results.get('messages', [])\n",
        "\n",
        "stats = {\n",
        "    \"Emergency\": 0,\n",
        "    \"Work\": 0,\n",
        "    \"Promotion\": 0,\n",
        "    \"Spam\": 0,\n",
        "    \"Not-Useful\": 0,\n",
        "    \"Personal\": 0\n",
        "}\n",
        "\n",
        "# Quick pass to classify all unread and build summary\n",
        "preview_cache = []  # store basic info so we don't refetch twice\n",
        "for msg in messages:\n",
        "    msg_id = msg['id']\n",
        "    # Assuming read_email is defined elsewhere to return subject, sender, body\n",
        "    subject, sender, date, body = extract_email_data(service, msg_id)\n",
        "    # Fix: Pass only subject and body to classify_email as per its definition\n",
        "    category = classify_email(subject, body)\n",
        "    stats[category] = stats.get(category, 0) + 1\n",
        "    preview_cache.append((msg_id, msg.get(\"threadId\"), subject, sender, body, category))\n",
        "\n",
        "print(\"\\nüì¨ UNREAD SUMMARY\")\n",
        "print(\"Total:\", len(messages))\n",
        "print(\"üö® Emergency:\", stats[\"Emergency\"])\n",
        "print(\"üíº Work:\", stats[\"Work\"])\n",
        "print(\"üì¢ Promotion:\", stats[\"Promotion\"])\n",
        "print(\"üóë Spam:\", stats[\"Spam\"])\n",
        "print(\"‚ùå Not Useful:\", stats[\"Not-Useful\"])\n",
        "print(\"üë§ Personal:\", stats[\"Personal\"])\n"
      ],
      "metadata": {
        "id": "mgJDcrQlZm5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be8f007-a19b-41ee-f669-bd0eadd2d9cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¨ UNREAD SUMMARY\n",
            "Total: 3\n",
            "üö® Emergency: 1\n",
            "üíº Work: 1\n",
            "üì¢ Promotion: 0\n",
            "üóë Spam: 1\n",
            "‚ùå Not Useful: 0\n",
            "üë§ Personal: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_email(subject, body):\n",
        "    prompt = f\"\"\"\n",
        "Classify this email into ONE of these categories:\n",
        "Emergency, Work, Promotion, Spam, Not-Useful, Personal\n",
        "\n",
        "Email:\n",
        "Subject: {subject}\n",
        "Body: {body}\n",
        "\n",
        "Return only the category name.\n",
        "\"\"\"\n",
        "    return llm_call(prompt)\n",
        "\n",
        "def generate_options(subject, sender, body):\n",
        "    prompt = f\"\"\"\n",
        "You are an intelligent email assistant.\n",
        "\n",
        "Email:\n",
        "Subject: {subject}\n",
        "From: {sender}\n",
        "Body:\n",
        "{body}\n",
        "\n",
        "Generate THREE reply options.\n",
        "Always sign every reply with this name: {YOUR_NAME}\n",
        "\n",
        "1. Formal professional reply\n",
        "2. Friendly casual reply\n",
        "3. Very short reply\n",
        "\n",
        "Format exactly like:\n",
        "\n",
        "Option 1:\n",
        "<text>\n",
        "\n",
        "Option 2:\n",
        "<text>\n",
        "\n",
        "Option 3:\n",
        "<text>\n",
        "\"\"\"\n",
        "    return llm_call(prompt)\n",
        "\n",
        "def is_no_reply(body, sender):\n",
        "    text = (body + \" \" + sender).lower()\n",
        "    return any(x in text for x in [\"do not reply\", \"no-reply\", \"noreply\", \"automated\"])\n",
        "\n",
        "def send_reply(service, to, subject, reply_text, thread_id):\n",
        "    msg = MIMEText(reply_text)\n",
        "    msg['to'] = to\n",
        "    msg['subject'] = \"Re: \" + subject\n",
        "    raw = base64.urlsafe_b64encode(msg.as_bytes()).decode()\n",
        "\n",
        "    service.users().messages().send(\n",
        "        userId='me',\n",
        "        body={'raw': raw, 'threadId': thread_id}\n",
        "    ).execute()\n"
      ],
      "metadata": {
        "id": "pPRh6cVcZ1Kk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmailState(TypedDict):\n",
        "    msg_id: str\n",
        "    thread_id: str\n",
        "    subject: str\n",
        "    sender: str\n",
        "    body: str\n",
        "    category: str\n",
        "    options: str\n",
        "    decision: str\n",
        "    selected_reply: str"
      ],
      "metadata": {
        "id": "SwHzyhOMNX47"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(EmailState)\n",
        "\n",
        "YOUR_NAME = \"Manoj Preetham V K\"\n",
        "\n",
        "def classify_node(state: EmailState) -> EmailState:\n",
        "    subject = state[\"subject\"]\n",
        "    body = state[\"body\"]\n",
        "    category = classify_email(subject, body)\n",
        "    return {\"category\": category}\n",
        "\n",
        "def filter_node(state: EmailState) -> EmailState:\n",
        "    if state[\"category\"] in [\"Spam\", \"Not-Useful\"]:\n",
        "        print(f\"Filtering out: {state['subject']} (Category: {state['category']})\")\n",
        "    return state # Always return the state dictionary\n",
        "\n",
        "def generate_node(state: EmailState) -> EmailState:\n",
        "    options = generate_options(\n",
        "        state[\"subject\"],\n",
        "        state[\"sender\"],\n",
        "        state[\"body\"],\n",
        "        state[\"category\"] # Pass the category here\n",
        "    )\n",
        "    return {\"options\": options}\n",
        "\n",
        "def hitl_node(state: EmailState) -> EmailState:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üìß SUBJECT: {state['subject']}\")\n",
        "    print(f\"üë§ FROM: {state['sender']}\")\n",
        "    print(f\"üè∑ Category: {state['category']}\")\n",
        "    print(\"üìù BODY:\\n\", state['body'][:500])\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if is_no_reply(state[\"body\"], state[\"sender\"]):\n",
        "        print(\"üö´ This is a no-reply / automated email. Skipping.\")\n",
        "        return {\"decision\": \"skip\"}\n",
        "\n",
        "    print(\"\\n\" + state[\"options\"])\n",
        "\n",
        "    choice = input(\"\\nChoose (1/2/3), 'e' to edit, or 's' to skip: \").strip().lower()\n",
        "\n",
        "    if choice == 's':\n",
        "        print(\"‚è≠Ô∏è Skipped\")\n",
        "        return {\"decision\": \"skip\"}\n",
        "\n",
        "    if choice == 'e':\n",
        "        edited = input(\"\\n‚úèÔ∏è Enter your edited reply:\\n\")\n",
        "        selected = edited\n",
        "    else:\n",
        "        if choice not in ['1', '2', '3']:\n",
        "            print(\"‚ö†Ô∏è Invalid choice. Skipped.\")\n",
        "            return {\"decision\": \"skip\"}\n",
        "\n",
        "        parts = state[\"options\"].split(\"Option \" + choice + \":\")\n",
        "        if len(parts) > 1:\n",
        "            selected = parts[1].split(\"Option\")[0].strip()\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Could not parse the selected option. Skipped.\")\n",
        "            return {\"decision\": \"skip\"}\n",
        "\n",
        "        # Save preference\n",
        "        style_map = {\"1\": \"Formal\", \"2\": \"Friendly\", \"3\": \"Short\"}\n",
        "        reply_prefs[state[\"category\"]] = style_map.get(choice, \"Unknown\")\n",
        "        save_preferences(reply_prefs)\n",
        "\n",
        "    return {\"decision\": choice, \"selected_reply\": selected}\n",
        "\n",
        "def action_node(state: EmailState):\n",
        "    if state[\"decision\"] == \"skip\":\n",
        "        return\n",
        "\n",
        "    if state[\"selected_reply\"]:\n",
        "        # Ensure the reply is signed if it's a custom edit without it\n",
        "        reply_text = state[\"selected_reply\"]\n",
        "        if state[\"decision\"] == 'e' and not reply_text.strip().endswith(YOUR_NAME):\n",
        "            reply_text += f\"\\n\\n{YOUR_NAME}\"\n",
        "\n",
        "        send_reply(\n",
        "            service,\n",
        "            to=state[\"sender\"],\n",
        "            subject=state[\"subject\"],\n",
        "            reply_text=reply_text,\n",
        "            thread_id=state[\"thread_id\"]\n",
        "        )\n",
        "\n",
        "        # Mark as read\n",
        "        service.users().messages().modify(\n",
        "            userId='me',\n",
        "            id=state[\"msg_id\"],\n",
        "            body={'removeLabelIds': ['UNREAD']}\n",
        "        ).execute()\n",
        "\n",
        "        print(\"üì§ Reply sent and email marked as read\")\n",
        "\n",
        "graph.add_node(\"classify\", classify_node)\n",
        "graph.add_node(\"filter\", filter_node)\n",
        "graph.add_node(\"generate\", generate_node)\n",
        "graph.add_node(\"hitl\", hitl_node)\n",
        "graph.add_node(\"action\", action_node)\n",
        "\n",
        "graph.set_entry_point(\"classify\")\n",
        "\n",
        "graph.add_edge(\"classify\", \"filter\")\n",
        "graph.add_conditional_edges(\n",
        "    \"filter\",\n",
        "    lambda state: END if state[\"category\"] in [\"Spam\", \"Not-Useful\"] else \"generate\"\n",
        ")\n",
        "graph.add_edge(\"generate\", \"hitl\")\n",
        "graph.add_edge(\"hitl\", \"action\")\n",
        "graph.add_edge(\"action\", END)\n",
        "\n",
        "agent = graph.compile(checkpointer=MemorySaver())"
      ],
      "metadata": {
        "id": "C0FUceogNloX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_id, thread_id, subject, sender, body in emails:\n",
        "    state = {\n",
        "        \"msg_id\": msg_id,\n",
        "        \"thread_id\": thread_id,\n",
        "        \"subject\": subject,\n",
        "        \"sender\": sender,\n",
        "        \"body\": body,\n",
        "    }\n",
        "    agent.invoke(\n",
        "        state,\n",
        "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXBmnyUXTh4V",
        "outputId": "a1c8e854-635d-4b6e-aaaa-21ccb9126d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üìß SUBJECT: Document verification\n",
            "üë§ FROM: Shane Gilbert S <shanegilbert1126@gmail.com>\n",
            "üè∑ Category: Work\n",
            "üìù BODY:\n",
            " hey manoj,this is regarding document verification for your educational\r\n",
            "visa approval.Kindly do submit the required documents immediately.\r\n",
            "regards govt.\r\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Option 1:  \n",
            "Dear Shane,  \n",
            "Thank you for your email regarding the document verification for my educational visa approval. I appreciate your prompt communication. I will ensure that the required documents are submitted immediately.  \n",
            "Best regards,  \n",
            "Manoj Preetham V K  \n",
            "\n",
            "Option 2:  \n",
            "Hey Shane,  \n",
            "Thanks for the heads up about the document verification! I‚Äôll get those documents sorted and sent over to you ASAP.  \n",
            "Cheers,  \n",
            "Manoj Preetham V K  \n",
            "\n",
            "Option 3:  \n",
            "Got it, will submit the documents soon.  \n",
            "Manoj Preetham V K\n",
            "\n",
            "Choose (1/2/3), 'e' to edit, or 's' to skip: 1\n",
            "üì§ Reply sent and email marked as read\n",
            "\n",
            "======================================================================\n",
            "üìß SUBJECT: Regarding intership\n",
            "üë§ FROM: Manoj Preetham v k <vkmanojpreetham2005@gmail.com>\n",
            "üè∑ Category: Work\n",
            "üìù BODY:\n",
            " Hey applicant,\n",
            " You have been shortlisted thankyou\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Option 1:  \n",
            "Dear [Recipient's Name],  \n",
            "\n",
            "Thank you for the update regarding my internship application. I am thrilled to hear that I have been shortlisted. Please let me know the next steps in the process.  \n",
            "\n",
            "Best regards,  \n",
            "Manoj Preetham V K  \n",
            "\n",
            "Option 2:  \n",
            "Hi there!  \n",
            "\n",
            "Thanks so much for the good news! I'm really excited to be shortlisted for the internship. Let me know what comes next!  \n",
            "\n",
            "Cheers,  \n",
            "Manoj Preetham V K  \n",
            "\n",
            "Option 3:  \n",
            "Thank you for the update.  \n",
            "\n",
            "Best,  \n",
            "Manoj Preetham V K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "PREF_FILE = \"reply_preferences.json\"\n",
        "\n",
        "def load_preferences():\n",
        "    if os.path.exists(PREF_FILE):\n",
        "        with open(PREF_FILE, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return {}\n",
        "\n",
        "def save_preferences(prefs):\n",
        "    with open(PREF_FILE, \"w\") as f:\n",
        "        json.dump(prefs, f, indent=2)\n",
        "\n",
        "reply_prefs = load_preferences()\n"
      ],
      "metadata": {
        "id": "_5ZHhbBjW_dm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_options(subject, sender, body, category):\n",
        "    preferred = reply_prefs.get(category)\n",
        "\n",
        "    hint = \"\"\n",
        "    if preferred:\n",
        "        hint = f\"\\nUser usually prefers **{preferred}** replies for {category} emails. Generate that style as Option 1.\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an intelligent email assistant.\n",
        "Always sign replies with: {YOUR_NAME}\n",
        "\n",
        "Email:\n",
        "Subject: {subject}\n",
        "From: {sender}\n",
        "Body:\n",
        "{body}\n",
        "\n",
        "{hint}\n",
        "\n",
        "Generate THREE reply options:\n",
        "\n",
        "1. Formal professional reply\n",
        "2. Friendly casual reply\n",
        "3. Very short reply\n",
        "\n",
        "Format exactly like:\n",
        "\n",
        "Option 1:\n",
        "<text>\n",
        "\n",
        "Option 2:\n",
        "<text>\n",
        "\n",
        "Option 3:\n",
        "<text>\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.4\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "nu8Xc9q4XCo2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PREF_FILE = \"reply_preferences.json\"\n"
      ],
      "metadata": {
        "id": "Ts0g--asXSte"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preferences():\n",
        "    if os.path.exists(PREF_FILE):\n",
        "        with open(PREF_FILE, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return {}\n",
        "\n",
        "def save_preferences(prefs):\n",
        "    with open(PREF_FILE, \"w\") as f:\n",
        "        json.dump(prefs, f, indent=2)\n",
        "\n",
        "reply_prefs = load_preferences()\n"
      ],
      "metadata": {
        "id": "igQZBwcOXgxE"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}