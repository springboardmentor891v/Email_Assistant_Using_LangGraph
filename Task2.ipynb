{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dary2XzSi5dH",
        "outputId": "b54bb352-a389-4009-eb99-c61184ca7f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.0.6)\n",
            "Requirement already satisfied: langchain in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: google-auth-oauthlib in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: google-api-python-client in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (2.188.0)\n",
            "Requirement already satisfied: langchain-google-genai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (4.1.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.2.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (2.12.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2.42.0,>=2.15.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth-oauthlib) (2.41.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-google-genai) (1.55.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.5)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (4.9.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain-openai google-auth-oauthlib google-api-python-client langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EunVT0Z-uM9U"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "from typing import TypedDict, Annotated, List, Literal\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Google API Imports\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "import pickle\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uqkAkFGBuyQI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=384278549136-eiug4ucl4ivh7tukmbqqtupv4b68bbhi.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A52342%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcalendar&state=QgNU4wIFyqR1WTGNZ4CaNctCk5GVzU&access_type=offline\n"
          ]
        }
      ],
      "source": [
        "# 1. SETUP GMAIL AUTHENTICATION\n",
        "SCOPES = [\n",
        "    'https://www.googleapis.com/auth/gmail.modify',\n",
        "    'https://www.googleapis.com/auth/calendar'\n",
        "]\n",
        "\n",
        "\n",
        "def get_gmail_service():\n",
        "    creds = None\n",
        "\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credentials1.json', SCOPES\n",
        "            )\n",
        "            creds = flow.run_local_server(port=0)\n",
        "\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    gmail_service = build('gmail', 'v1', credentials=creds)\n",
        "    calendar_service = build('calendar', 'v3', credentials=creds)\n",
        "\n",
        "    return gmail_service, calendar_service\n",
        "\n",
        "\n",
        "service, calendar_service = get_gmail_service()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_event(calendar_service, summary, start_dt, end_dt, attendees=None):\n",
        "    if not summary or not start_dt or not end_dt:\n",
        "        print(\"Skipping event creation: missing required info\")\n",
        "        return None\n",
        "\n",
        "    event = {\n",
        "        \"summary\": summary,\n",
        "        \"start\": {\"dateTime\": start_dt, \"timeZone\": \"Asia/Kolkata\"},\n",
        "        \"end\": {\"dateTime\": end_dt, \"timeZone\": \"Asia/Kolkata\"},\n",
        "    }\n",
        "\n",
        "    if attendees:\n",
        "        event[\"attendees\"] = [{\"email\": email} for email in attendees]\n",
        "\n",
        "    try:\n",
        "        created_event = calendar_service.events().insert(\n",
        "            calendarId='primary', body=event).execute()\n",
        "        print(\"Event created:\", created_event.get('htmlLink'))\n",
        "        return created_event\n",
        "    except HttpError as error:\n",
        "        print(\"Calendar API error:\", error)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pZQByH3VI227"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.modify']\n",
        "\n",
        "def get_gmail_service():\n",
        "    creds = None\n",
        "\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file(\n",
        "            'token.json', SCOPES\n",
        "        )\n",
        "\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credential.json',\n",
        "                SCOPES,\n",
        "                redirect_uri='urn:ietf:wg:oauth:2.0:oob'  \n",
        "            )\n",
        "\n",
        "            auth_url, _ = flow.authorization_url(\n",
        "                prompt='consent'\n",
        "            )\n",
        "\n",
        "            print(\"\\nðŸ”— OPEN THIS URL IN YOUR BROWSER:\\n\")\n",
        "            print(auth_url)\n",
        "\n",
        "            code = input(\"\\nðŸ“Œ Paste the authorization code here: \")\n",
        "            flow.fetch_token(code=code)\n",
        "            creds = flow.credentials\n",
        "\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    return build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "service = get_gmail_service()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_inbox(service, max_results=5):\n",
        "    results = service.users().messages().list(\n",
        "        userId='me',\n",
        "        labelIds=['INBOX'],\n",
        "        maxResults=max_results\n",
        "    ).execute()\n",
        "\n",
        "    messages = results.get('messages', [])\n",
        "\n",
        "    if not messages:\n",
        "        print(\"No messages found.\")\n",
        "        return\n",
        "\n",
        "    for msg in messages:\n",
        "        msg_id = msg['id']\n",
        "        message = service.users().messages().get(\n",
        "            userId='me',\n",
        "            id=msg_id,\n",
        "            format='metadata',\n",
        "            metadataHeaders=['From', 'Subject']\n",
        "        ).execute()\n",
        "\n",
        "        headers = message['payload']['headers']\n",
        "        email_data = {}\n",
        "\n",
        "        for h in headers:\n",
        "            email_data[h['name']] = h['value']\n",
        "\n",
        "        print(\"\\nðŸ“© New Email\")\n",
        "        print(\"From:\", email_data.get('From'))\n",
        "        print(\"Subject:\", email_data.get('Subject'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Project Update\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Interview Discussion\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Application for Internship Opportunity\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Request for Information\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: Fatimi Bee <b230955@skit.ac.in>\n",
            "Subject: regarding request\n"
          ]
        }
      ],
      "source": [
        "read_inbox(service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models available for this key:\n",
            "gpt-3.5-turbo\n",
            "gpt-5.2-codex\n",
            "gpt-4o-mini-tts-2025-12-15\n",
            "gpt-realtime-mini-2025-12-15\n",
            "gpt-audio-mini-2025-12-15\n",
            "chatgpt-image-latest\n",
            "davinci-002\n",
            "babbage-002\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "dall-e-3\n",
            "dall-e-2\n",
            "gpt-3.5-turbo-1106\n",
            "tts-1-hd\n",
            "tts-1-1106\n",
            "tts-1-hd-1106\n",
            "text-embedding-3-small\n",
            "text-embedding-3-large\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4o-2024-08-06\n",
            "gpt-4o-audio-preview\n",
            "omni-moderation-latest\n",
            "omni-moderation-2024-09-26\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "o1-2024-12-17\n",
            "o1\n",
            "gpt-4o-mini-audio-preview\n",
            "o3-mini\n",
            "o3-mini-2025-01-31\n",
            "gpt-4o-2024-11-20\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-transcribe\n",
            "gpt-4o-mini-transcribe\n",
            "gpt-4o-mini-tts\n",
            "o3-2025-04-16\n",
            "o4-mini-2025-04-16\n",
            "o3\n",
            "o4-mini\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4.1\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-4.1-nano-2025-04-14\n",
            "gpt-4.1-nano\n",
            "gpt-image-1\n",
            "gpt-4o-audio-preview-2025-06-03\n",
            "gpt-4o-transcribe-diarize\n",
            "gpt-5-chat-latest\n",
            "gpt-5-2025-08-07\n",
            "gpt-5\n",
            "gpt-5-mini-2025-08-07\n",
            "gpt-5-mini\n",
            "gpt-5-nano-2025-08-07\n",
            "gpt-5-nano\n",
            "gpt-audio-2025-08-28\n",
            "gpt-realtime\n",
            "gpt-realtime-2025-08-28\n",
            "gpt-audio\n",
            "gpt-5-codex\n",
            "gpt-image-1-mini\n",
            "gpt-5-pro-2025-10-06\n",
            "gpt-5-pro\n",
            "gpt-audio-mini\n",
            "gpt-audio-mini-2025-10-06\n",
            "gpt-5-search-api\n",
            "gpt-realtime-mini\n",
            "gpt-realtime-mini-2025-10-06\n",
            "sora-2\n",
            "sora-2-pro\n",
            "gpt-5-search-api-2025-10-14\n",
            "gpt-5.1-chat-latest\n",
            "gpt-5.1-2025-11-13\n",
            "gpt-5.1\n",
            "gpt-5.1-codex\n",
            "gpt-5.1-codex-mini\n",
            "gpt-5.1-codex-max\n",
            "gpt-image-1.5\n",
            "gpt-5.2-2025-12-11\n",
            "gpt-5.2\n",
            "gpt-5.2-pro-2025-12-11\n",
            "gpt-5.2-pro\n",
            "gpt-5.2-chat-latest\n",
            "gpt-4o-mini-transcribe-2025-12-15\n",
            "gpt-4o-mini-transcribe-2025-03-20\n",
            "gpt-4o-mini-tts-2025-03-20\n",
            "whisper-1\n",
            "tts-1\n",
            "gpt-3.5-turbo-16k\n",
            "text-embedding-ada-002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Read API key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "try:\n",
        "    # List models available for this key\n",
        "    models = client.models.list()\n",
        "\n",
        "    print(\"Models available for this key:\")\n",
        "    for model in models.data:\n",
        "        print(model.id)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: langgraph in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.0.6)\n",
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: python-dotenv in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain) (2.12.5)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langgraph langchain-openai python-dotenv \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (1.2.7)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_llm():\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    from langchain_openai import ChatOpenAI\n",
        "  # LangChain OpenAI chat model\n",
        "\n",
        "    # Load environment variables from .env\n",
        "    load_dotenv()\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # Make sure this is set in your .env\n",
        "\n",
        "    if not OPENAI_API_KEY:\n",
        "        raise ValueError(\"Please set OPENAI_API_KEY in your .env file\")\n",
        "\n",
        "    # Initialize OpenAI LLM via LangChain\n",
        "    llm = ChatOpenAI(\n",
        "        model_name=\"gpt-3.5-turbo\",  # free-tier model\n",
        "        temperature=0,\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "    )\n",
        "\n",
        "    return llm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_email_prompt(user_prompt: str):\n",
        "    from langchain_core.prompts import (\n",
        "        ChatPromptTemplate,\n",
        "        SystemMessagePromptTemplate,\n",
        "        HumanMessagePromptTemplate\n",
        "    )\n",
        "\n",
        "    system_text = f\"\"\"\n",
        "You are an AI email assistant.\n",
        "\n",
        "User instructions:\n",
        "{user_prompt}\n",
        "\n",
        "IMPORTANT RULES:\n",
        "- Output STRICT JSON only\n",
        "- Do NOT use markdown\n",
        "- Do not add names or signatures\n",
        "\n",
        "JSON FORMAT:\n",
        "The AI must return a JSON object with these keys:\n",
        "- action: string, one of \"reply\", \"ignore\", or \"schedule\"\n",
        "- reply: string, the plain text email reply (only if action is \"reply\")\n",
        "- event: object with keys \"title\", \"date\", \"start_time\", \"end_time\" (only if action is \"schedule\")\n",
        "\"\"\"\n",
        "\n",
        "    system_msg = SystemMessagePromptTemplate.from_template(system_text)\n",
        "\n",
        "    human_msg = HumanMessagePromptTemplate.from_template(\n",
        "        \"Subject: {subject}\\nFrom: {sender}\\nBody: {body}\"\n",
        "    )\n",
        "\n",
        "    return ChatPromptTemplate.from_messages([system_msg, human_msg])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def fetch_unread_emails(service, max_results=5):\n",
        "    return service.users().messages().list(\n",
        "        userId=\"me\",\n",
        "        labelIds=[\"UNREAD\"],\n",
        "        maxResults=max_results\n",
        "    ).execute().get(\"messages\", [])\n",
        "\n",
        "def extract_email(service, msg_id):\n",
        "    msg = service.users().messages().get(\n",
        "        userId=\"me\",\n",
        "        id=msg_id,\n",
        "        format=\"full\"\n",
        "    ).execute()\n",
        "\n",
        "    headers = msg[\"payload\"][\"headers\"]\n",
        "    subject = sender = \"\"\n",
        "\n",
        "    for h in headers:\n",
        "        if h[\"name\"] == \"Subject\":\n",
        "            subject = h[\"value\"]\n",
        "        elif h[\"name\"] == \"From\":\n",
        "            sender = h[\"value\"]\n",
        "\n",
        "    body = \"\"\n",
        "    payload = msg[\"payload\"]\n",
        "\n",
        "    if \"parts\" in payload:\n",
        "        for part in payload[\"parts\"]:\n",
        "            if part[\"mimeType\"] == \"text/plain\":\n",
        "                data = part[\"body\"].get(\"data\")\n",
        "                if data:\n",
        "                    body = base64.urlsafe_b64decode(data).decode()\n",
        "    else:\n",
        "        data = payload[\"body\"].get(\"data\")\n",
        "        if data:\n",
        "            body = base64.urlsafe_b64decode(data).decode()\n",
        "\n",
        "    return subject, sender, body, msg[\"threadId\"]\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_email_body(body: str) -> str:\n",
        "    # Remove markdown JSON blocks\n",
        "    body = re.sub(r\"```json[\\s\\S]*?```\", \"\", body, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove quoted replies (Gmail style)\n",
        "    body = re.split(r\"\\nOn .* wrote:\", body)[0]\n",
        "\n",
        "    # Remove lines starting with >\n",
        "    body = \"\\n\".join(\n",
        "        line for line in body.splitlines()\n",
        "        if not line.strip().startswith(\">\")\n",
        "    )\n",
        "\n",
        "    return body.strip()\n",
        "\n",
        "def send_reply(service, to, subject, reply, thread_id):\n",
        "    message = MIMEText(reply)\n",
        "    message[\"to\"] = to\n",
        "    message[\"subject\"] = \"Re: \" + subject\n",
        "\n",
        "    raw = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
        "\n",
        "    service.users().messages().send(\n",
        "        userId=\"me\",\n",
        "        body={\"raw\": raw, \"threadId\": thread_id}\n",
        "    ).execute()\n",
        "\n",
        "def mark_read(service, msg_id):\n",
        "    service.users().messages().modify(\n",
        "        userId=\"me\",\n",
        "        id=msg_id,\n",
        "        body={\"removeLabelIds\": [\"UNREAD\"]}\n",
        "    ).execute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def process_all_unread_emails(service, user_prompt, calendar_service=None, max_results=20):\n",
        "    \"\"\"\n",
        "    Process unread emails using AI and take actions (reply, schedule, ignore).\n",
        "\n",
        "    Args:\n",
        "        service: Gmail API service object\n",
        "        user_prompt: Base instruction for AI\n",
        "        calendar_service: Optional, Google Calendar service for scheduling\n",
        "        max_results: Number of emails to fetch\n",
        "    \"\"\"\n",
        "    # Build prompt and LLM\n",
        "    prompt = build_email_prompt(user_prompt)\n",
        "    llm = load_llm()\n",
        "\n",
        "    # Fetch unread emails\n",
        "    emails = fetch_unread_emails(service, max_results=max_results)\n",
        "    print(f\"\\nðŸ“¬ Total unread emails: {len(emails)}\\n\")\n",
        "\n",
        "    if not emails:\n",
        "        print(\"ðŸŽ‰ No unread emails.\")\n",
        "        return\n",
        "\n",
        "    for idx, msg in enumerate(emails, start=1):\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"ðŸ“§ Processing email {idx}/{len(emails)}\")\n",
        "\n",
        "        # Extract email details\n",
        "        subject, sender, body, thread_id = extract_email(service, msg[\"id\"])\n",
        "        body = clean_email_body(body)\n",
        "\n",
        "        print(f\"From   : {sender}\")\n",
        "        print(f\"Subject: {subject}\")\n",
        "        print(\"Body preview:\")\n",
        "        print(body[:300])\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # ---- AI RESPONSE ----\n",
        "        try:\n",
        "            ai_response = llm.invoke(\n",
        "                prompt.format_prompt(\n",
        "                    subject=subject,\n",
        "                    sender=sender,\n",
        "                    body=body,\n",
        "                    action=\"Reply\"  # Required placeholder\n",
        "                ).to_messages()\n",
        "            ).content\n",
        "        except KeyError as e:\n",
        "            print(f\"âŒ KeyError in prompt formatting: {e}. Skipping email.\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ AI invocation failed: {e}. Skipping email.\")\n",
        "            continue\n",
        "\n",
        "        # Parse AI JSON safely\n",
        "        try:\n",
        "            result = json.loads(ai_response)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"âŒ AI returned invalid JSON. Skipping email.\")\n",
        "            continue\n",
        "\n",
        "        action = result.get(\"action\", \"ignore\")  # Default to ignore\n",
        "        reply = result.get(\"reply\", \"\")\n",
        "\n",
        "        # ---- Handle scheduled event ----\n",
        "        if action == \"schedule\":\n",
        "            if calendar_service is None:\n",
        "                print(\"âŒ Calendar service not provided. Cannot schedule event.\")\n",
        "                continue\n",
        "\n",
        "            event = result.get(\"event\", {})\n",
        "            start_dt = f\"{event.get('date','')}T{event.get('start_time','00:00')}:00\"\n",
        "            end_dt = f\"{event.get('date','')}T{event.get('end_time','00:00')}:00\"\n",
        "\n",
        "            create_event(\n",
        "                calendar_service,\n",
        "                title=event.get(\"title\", \"Meeting\"),\n",
        "                description=body,\n",
        "                start_dt=start_dt,\n",
        "                end_dt=end_dt\n",
        "            )\n",
        "\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Event scheduled & email marked as read\")\n",
        "            continue\n",
        "\n",
        "        # ---- Handle ignored email ----\n",
        "        if action == \"ignore\":\n",
        "            print(\"ðŸš« AI chose to ignore this email.\")\n",
        "            continue\n",
        "\n",
        "        # ---- Draft reply ----\n",
        "        print(\"\\nðŸ¤– AI Draft Reply\")\n",
        "        print(\"-\" * 50)\n",
        "        print(reply)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        decision = input(\"Send this reply? (y / edit / skip): \").lower()\n",
        "\n",
        "        if decision == \"y\":\n",
        "            send_reply(service, sender, subject, reply, thread_id)\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Reply sent & marked as read\")\n",
        "\n",
        "        elif decision == \"edit\":\n",
        "            edited = input(\"\\nâœï¸ Enter your edited reply:\\n\")\n",
        "            send_reply(service, sender, subject, edited, thread_id)\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Edited reply sent & marked as read\")\n",
        "\n",
        "        else:\n",
        "            print(\"â­ï¸ Skipped (email remains unread)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“¬ Total unread emails: 1\n",
            "\n",
            "======================================================================\n",
            "ðŸ“§ Processing email 1/1\n",
            "From   : fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Interview Discussion\n",
            "Body preview:\n",
            "Hi,\n",
            "\n",
            "We would like to schedule an interview call with you on\n",
            "5th February at 10:00 AM.\n",
            "\n",
            "Please confirm your availability.\n",
            "\n",
            "Thanks,\n",
            "HR Team\n",
            "======================================================================\n",
            "\n",
            "ðŸ¤– AI Draft Reply\n",
            "--------------------------------------------------\n",
            "Hi,\n",
            "\n",
            "Thank you for the invitation. I confirm my availability for an interview call on February 5th at 10:00 AM.\n",
            "\n",
            "Looking forward to it.\n",
            "--------------------------------------------------\n",
            "âœ… Reply sent & marked as read\n"
          ]
        }
      ],
      "source": [
        "USER_PROMPT = \"\"\"\n",
        "Reply only to genuine emails.\n",
        "Ignore promotions and job ads.\n",
        "Be polite, concise, and human-like.\n",
        "Do not add name or signature.\n",
        "\"\"\"\n",
        "\n",
        "process_all_unread_emails(service, USER_PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_state_schema():\n",
        "    from typing import TypedDict, Optional\n",
        "\n",
        "    class EmailState(TypedDict):\n",
        "        subject: str\n",
        "        sender: str\n",
        "        body: str\n",
        "        thread_id: str\n",
        "        decision: dict\n",
        "        final_reply: Optional[str]\n",
        "\n",
        "    return EmailState\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ai_decision_node(state, prompt, llm):\n",
        "    import json\n",
        "    import re\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    response = chain.invoke({\n",
        "        \"subject\": state[\"subject\"],\n",
        "        \"sender\": state[\"sender\"],\n",
        "        \"body\": state[\"body\"]\n",
        "    })\n",
        "\n",
        "    raw = response.content.strip()\n",
        "\n",
        "    # ðŸ”‘ REMOVE ```json ``` wrappers\n",
        "    raw = re.sub(r\"^```json\\s*\", \"\", raw)\n",
        "    raw = re.sub(r\"^```\\s*\", \"\", raw)\n",
        "    raw = re.sub(r\"\\s*```$\", \"\", raw)\n",
        "\n",
        "    try:\n",
        "        decision = json.loads(raw)\n",
        "    except Exception as e:\n",
        "        print(\"âŒ JSON parse failed:\", e)\n",
        "        print(\"RAW OUTPUT:\\n\", response.content)\n",
        "        decision = {\"action\": \"ignore\"}\n",
        "\n",
        "    return {\"decision\": decision}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def human_confirmation_node(state):\n",
        "    reply = state[\"decision\"].get(\"reply\")\n",
        "\n",
        "    print(\"\\nðŸ¤– AI Draft Reply\")\n",
        "    print(\"-\" * 50)\n",
        "    print(reply)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Send reply? (y / n / edit): \").strip().lower()\n",
        "\n",
        "        if choice == \"y\":\n",
        "            return {\"final_reply\": reply}\n",
        "\n",
        "        if choice == \"n\":\n",
        "            return {\"final_reply\": None}\n",
        "\n",
        "        if choice == \"edit\":\n",
        "            print(\"\\nâœï¸ Enter edited reply (empty line to finish):\")\n",
        "            lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if not line:\n",
        "                    break\n",
        "                lines.append(line)\n",
        "            return {\"final_reply\": \"\\n\".join(lines)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calendar_node_factory(calendar_service):\n",
        "    def calendar_node(state):\n",
        "        event = state[\"decision\"].get(\"event\", {})\n",
        "\n",
        "        start_dt = f\"{event['date']}T{event['start_time']}:00\"\n",
        "        end_dt = f\"{event['date']}T{event['end_time']}:00\"\n",
        "\n",
        "        create_event(\n",
        "            calendar_service,\n",
        "            title=event.get(\"title\", \"Meeting\"),\n",
        "            description=state[\"body\"],\n",
        "            start_dt=start_dt,\n",
        "            end_dt=end_dt\n",
        "        )\n",
        "\n",
        "        return {}\n",
        "\n",
        "    return calendar_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def send_node_factory(service):\n",
        "    def send_node(state):\n",
        "        if state.get(\"final_reply\"):\n",
        "            send_reply(\n",
        "                service,\n",
        "                state[\"sender\"],\n",
        "                state[\"subject\"],\n",
        "                state[\"final_reply\"],\n",
        "                state[\"thread_id\"]\n",
        "            )\n",
        "            print(\"âœ… Reply sent\")\n",
        "        else:\n",
        "            print(\"â­ï¸ Skipped\")\n",
        "\n",
        "        return {}\n",
        "    return send_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_email_graph(user_prompt: str, service, calendar_service):\n",
        "    from langgraph.graph import StateGraph, END\n",
        "\n",
        "    EmailState = get_state_schema()\n",
        "    llm = load_llm()\n",
        "    prompt = build_email_prompt(user_prompt)\n",
        "\n",
        "    graph = StateGraph(EmailState)\n",
        "\n",
        "    graph.add_node(\n",
        "        \"ai_decision\",\n",
        "        lambda s: ai_decision_node(s, prompt, llm)\n",
        "    )\n",
        "\n",
        "    graph.add_node(\"human_confirm\", human_confirmation_node)\n",
        "    graph.add_node(\"send\", send_node_factory(service))\n",
        "    graph.add_node(\"calendar\", calendar_node_factory(calendar_service))\n",
        "\n",
        "    graph.set_entry_point(\"ai_decision\")\n",
        "\n",
        "    graph.add_conditional_edges(\n",
        "        \"ai_decision\",\n",
        "        lambda s: s[\"decision\"][\"action\"],\n",
        "        {\n",
        "            \"reply\": \"human_confirm\",\n",
        "            \"ignore\": END,\n",
        "            \"schedule\": \"calendar\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    graph.add_edge(\"human_confirm\", \"send\")\n",
        "    graph.add_edge(\"send\", END)\n",
        "    graph.add_edge(\"calendar\", END)\n",
        "\n",
        "    return graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_email_assistant(service, user_prompt, max_results=3):\n",
        "    # Build LangGraph app\n",
        "    app = build_email_graph(user_prompt, service, calendar_service)\n",
        "\n",
        "\n",
        "    # Fetch unread emails\n",
        "    emails = fetch_unread_emails(service, max_results=max_results)\n",
        "\n",
        "    if not emails:\n",
        "        print(\"ðŸ“­ No unread emails found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nðŸ“¬ Total unread emails: {len(emails)}\")\n",
        "\n",
        "    for i, msg in enumerate(emails, start=1):\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"ðŸ“§ Processing email {i}/{len(emails)}\")\n",
        "\n",
        "        subject, sender, body, thread_id = extract_email(service, msg[\"id\"])\n",
        "        body = clean_email_body(body)\n",
        "\n",
        "        print(\"From   :\", sender)\n",
        "        print(\"Subject:\", subject)\n",
        "        print(\"Body preview:\")\n",
        "        print(body[:500])\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Initial state for graph\n",
        "        state = {\n",
        "            \"subject\": subject,\n",
        "            \"sender\": sender,\n",
        "            \"body\": body,\n",
        "            \"thread_id\": thread_id,\n",
        "        }\n",
        "\n",
        "        # Run LangGraph\n",
        "        app.invoke(state)\n",
        "\n",
        "        # Mark as read ONLY after graph completes\n",
        "        mark_read(service, msg[\"id\"])\n",
        "        print(\"ðŸ“© Email marked as read\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“¬ Total unread emails: 1\n",
            "\n",
            "======================================================================\n",
            "ðŸ“§ Processing email 1/1\n",
            "From   : fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Project Discussion Meeting\n",
            "Body preview:\n",
            "Hi Saniya,\n",
            "\n",
            "I hope you are doing well. Can we schedule a meeting tomorrow at 3:00 PM\n",
            "IST to discuss the Infosys Email Assistant project progress?\n",
            "Please let me know if that time works for you or suggest another slot.\n",
            "\n",
            "Thanks,\n",
            "Fatimi\n",
            "======================================================================\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m USER_PROMPT = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mReply only to genuine emails.\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mIgnore promotions and job ads.\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mSchedule meetings if the email discusses a meeting, call, interview, or appointment.\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mrun_email_assistant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_PROMPT\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mrun_email_assistant\u001b[39m\u001b[34m(service, user_prompt, max_results)\u001b[39m\n\u001b[32m     29\u001b[39m state = {\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m\"\u001b[39m: subject,\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msender\u001b[39m\u001b[33m\"\u001b[39m: sender,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m: body,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: thread_id,\n\u001b[32m     34\u001b[39m }\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Run LangGraph\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Mark as read ONLY after graph completes\u001b[39;00m\n\u001b[32m     40\u001b[39m mark_read(service, msg[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mbuild_email_graph.<locals>.<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m      6\u001b[39m prompt = build_email_prompt(user_prompt)\n\u001b[32m      8\u001b[39m graph = StateGraph(EmailState)\n\u001b[32m     10\u001b[39m graph.add_node(\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mai_decision\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[43mai_decision_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mhuman_confirm\u001b[39m\u001b[33m\"\u001b[39m, human_confirmation_node)\n\u001b[32m     16\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33msend\u001b[39m\u001b[33m\"\u001b[39m, send_node_factory(service))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mai_decision_node\u001b[39m\u001b[34m(state, prompt, llm)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      5\u001b[39m chain = prompt | llm\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msubject\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msubject\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msender\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msender\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbody\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbody\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m raw = response.content.strip()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ðŸ”‘ REMOVE ```json ``` wrappers\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3151\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3149\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3150\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3151\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3152\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3153\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1386\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1385\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1389\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1390\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1391\u001b[39m ):\n\u001b[32m   1392\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1381\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1374\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1375\u001b[39m             response,\n\u001b[32m   1376\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1377\u001b[39m             metadata=generation_info,\n\u001b[32m   1378\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1379\u001b[39m         )\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m         response = raw_response.parse()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Desktop\\Infosys\\Email_Assistant_Using_LangGraph\\venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
            "During task with name 'ai_decision' and id '6d94ba64-9d76-cffd-1b54-1174ecafb0c1'"
          ]
        }
      ],
      "source": [
        "USER_PROMPT = \"\"\"\n",
        "Reply only to genuine emails.\n",
        "Ignore promotions and job ads.\n",
        "Schedule meetings if the email discusses a meeting, call, interview, or appointment.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "run_email_assistant(service, USER_PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
