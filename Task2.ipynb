{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dary2XzSi5dH",
        "outputId": "b54bb352-a389-4009-eb99-c61184ca7f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.0.6)\n",
            "Requirement already satisfied: langchain in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: google-auth-oauthlib in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: google-api-python-client in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (2.188.0)\n",
            "Requirement already satisfied: langchain-google-genai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (4.1.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.2.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (2.12.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2.42.0,>=2.15.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth-oauthlib) (2.41.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.53.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-google-genai) (1.55.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.5)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (4.9.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2.42.0,>=2.15.0->google-auth-oauthlib) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain-openai google-auth-oauthlib google-api-python-client langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from memoryStore import (\n",
        "    init_memory,\n",
        "    save_email_memory,\n",
        "    get_sender_history,\n",
        "    get_conn\n",
        ")\n",
        "init_memory()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EunVT0Z-uM9U"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "from typing import TypedDict, Annotated, List, Literal\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Google API Imports\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "import pickle\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uqkAkFGBuyQI"
      },
      "outputs": [],
      "source": [
        "# 1. SETUP GMAIL AUTHENTICATION\n",
        "SCOPES = [\n",
        "    'https://www.googleapis.com/auth/gmail.modify',\n",
        "    'https://www.googleapis.com/auth/calendar'\n",
        "]\n",
        "\n",
        "\n",
        "def get_gmail_service():\n",
        "    creds = None\n",
        "\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credentials1.json', SCOPES\n",
        "            )\n",
        "            creds = flow.run_local_server(port=0)\n",
        "\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    gmail_service = build('gmail', 'v1', credentials=creds)\n",
        "    calendar_service = build('calendar', 'v3', credentials=creds)\n",
        "\n",
        "    return gmail_service, calendar_service\n",
        "\n",
        "\n",
        "service, calendar_service = get_gmail_service()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_event(calendar_service, summary, start_dt, end_dt, attendees=None):\n",
        "    if not summary or not start_dt or not end_dt:\n",
        "        print(\"Skipping event creation: missing required info\")\n",
        "        return None\n",
        "\n",
        "    event = {\n",
        "        \"summary\": summary,\n",
        "        \"start\": {\"dateTime\": start_dt, \"timeZone\": \"Asia/Kolkata\"},\n",
        "        \"end\": {\"dateTime\": end_dt, \"timeZone\": \"Asia/Kolkata\"},\n",
        "    }\n",
        "\n",
        "    if attendees:\n",
        "        event[\"attendees\"] = [{\"email\": email} for email in attendees]\n",
        "\n",
        "    try:\n",
        "        created_event = calendar_service.events().insert(\n",
        "            calendarId='primary', body=event).execute()\n",
        "        print(\"Event created:\", created_event.get('htmlLink'))\n",
        "        return created_event\n",
        "    except HttpError as error:\n",
        "        print(\"Calendar API error:\", error)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pZQByH3VI227"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.modify']\n",
        "\n",
        "def get_gmail_service():\n",
        "    creds = None\n",
        "\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file(\n",
        "            'token.json', SCOPES\n",
        "        )\n",
        "\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'credential.json',\n",
        "                SCOPES,\n",
        "                redirect_uri='urn:ietf:wg:oauth:2.0:oob'  \n",
        "            )\n",
        "\n",
        "            auth_url, _ = flow.authorization_url(\n",
        "                prompt='consent'\n",
        "            )\n",
        "\n",
        "            print(\"\\nðŸ”— OPEN THIS URL IN YOUR BROWSER:\\n\")\n",
        "            print(auth_url)\n",
        "\n",
        "            code = input(\"\\nðŸ“Œ Paste the authorization code here: \")\n",
        "            flow.fetch_token(code=code)\n",
        "            creds = flow.credentials\n",
        "\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "\n",
        "    return build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "service = get_gmail_service()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_inbox(service, max_results=5):\n",
        "    results = service.users().messages().list(\n",
        "        userId='me',\n",
        "        labelIds=['INBOX'],\n",
        "        maxResults=max_results\n",
        "    ).execute()\n",
        "\n",
        "    messages = results.get('messages', [])\n",
        "\n",
        "    if not messages:\n",
        "        print(\"No messages found.\")\n",
        "        return\n",
        "\n",
        "    for msg in messages:\n",
        "        msg_id = msg['id']\n",
        "        message = service.users().messages().get(\n",
        "            userId='me',\n",
        "            id=msg_id,\n",
        "            format='metadata',\n",
        "            metadataHeaders=['From', 'Subject']\n",
        "        ).execute()\n",
        "\n",
        "        headers = message['payload']['headers']\n",
        "        email_data = {}\n",
        "\n",
        "        for h in headers:\n",
        "            email_data[h['name']] = h['value']\n",
        "\n",
        "        print(\"\\nðŸ“© New Email\")\n",
        "        print(\"From:\", email_data.get('From'))\n",
        "        print(\"Subject:\", email_data.get('Subject'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Follow-Up on Meeting Scheduling\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: request fo meeting scheduling\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Meeting Request\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: lets connect\n",
            "\n",
            "ðŸ“© New Email\n",
            "From: fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Project Discussion Meeting\n"
          ]
        }
      ],
      "source": [
        "read_inbox(service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models available for this key:\n",
            "gpt-3.5-turbo\n",
            "gpt-5.2-codex\n",
            "gpt-4o-mini-tts-2025-12-15\n",
            "gpt-realtime-mini-2025-12-15\n",
            "gpt-audio-mini-2025-12-15\n",
            "chatgpt-image-latest\n",
            "davinci-002\n",
            "babbage-002\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "dall-e-3\n",
            "dall-e-2\n",
            "gpt-3.5-turbo-1106\n",
            "tts-1-hd\n",
            "tts-1-1106\n",
            "tts-1-hd-1106\n",
            "text-embedding-3-small\n",
            "text-embedding-3-large\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4o-2024-08-06\n",
            "gpt-4o-audio-preview\n",
            "omni-moderation-latest\n",
            "omni-moderation-2024-09-26\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "o1-2024-12-17\n",
            "o1\n",
            "gpt-4o-mini-audio-preview\n",
            "o3-mini\n",
            "o3-mini-2025-01-31\n",
            "gpt-4o-2024-11-20\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-transcribe\n",
            "gpt-4o-mini-transcribe\n",
            "gpt-4o-mini-tts\n",
            "o3-2025-04-16\n",
            "o4-mini-2025-04-16\n",
            "o3\n",
            "o4-mini\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4.1\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-4.1-nano-2025-04-14\n",
            "gpt-4.1-nano\n",
            "gpt-image-1\n",
            "gpt-4o-audio-preview-2025-06-03\n",
            "gpt-4o-transcribe-diarize\n",
            "gpt-5-chat-latest\n",
            "gpt-5-2025-08-07\n",
            "gpt-5\n",
            "gpt-5-mini-2025-08-07\n",
            "gpt-5-mini\n",
            "gpt-5-nano-2025-08-07\n",
            "gpt-5-nano\n",
            "gpt-audio-2025-08-28\n",
            "gpt-realtime\n",
            "gpt-realtime-2025-08-28\n",
            "gpt-audio\n",
            "gpt-5-codex\n",
            "gpt-image-1-mini\n",
            "gpt-5-pro-2025-10-06\n",
            "gpt-5-pro\n",
            "gpt-audio-mini\n",
            "gpt-audio-mini-2025-10-06\n",
            "gpt-5-search-api\n",
            "gpt-realtime-mini\n",
            "gpt-realtime-mini-2025-10-06\n",
            "sora-2\n",
            "sora-2-pro\n",
            "gpt-5-search-api-2025-10-14\n",
            "gpt-5.1-chat-latest\n",
            "gpt-5.1-2025-11-13\n",
            "gpt-5.1\n",
            "gpt-5.1-codex\n",
            "gpt-5.1-codex-mini\n",
            "gpt-5.1-codex-max\n",
            "gpt-image-1.5\n",
            "gpt-5.2-2025-12-11\n",
            "gpt-5.2\n",
            "gpt-5.2-pro-2025-12-11\n",
            "gpt-5.2-pro\n",
            "gpt-5.2-chat-latest\n",
            "gpt-4o-mini-transcribe-2025-12-15\n",
            "gpt-4o-mini-transcribe-2025-03-20\n",
            "gpt-4o-mini-tts-2025-03-20\n",
            "whisper-1\n",
            "tts-1\n",
            "gpt-3.5-turbo-16k\n",
            "text-embedding-ada-002\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Read API key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
        "\n",
        "# Create OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "try:\n",
        "    # List models available for this key\n",
        "    models = client.models.list()\n",
        "\n",
        "    print(\"Models available for this key:\")\n",
        "    for model in models.data:\n",
        "        print(model.id)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.3)\n",
            "Requirement already satisfied: langgraph in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.0.6)\n",
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: python-dotenv in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain) (2.12.5)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langgraph langchain-openai python-dotenv \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (1.2.7)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.2)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (0.8.6)\n",
            "Requirement already satisfied: python-dotenv in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (1.2.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (2.188.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (2.41.1)\n",
            "Requirement already satisfied: protobuf in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
            "Requirement already satisfied: tqdm in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: colorama in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\desktop\\infosys\\email_assistant_using_langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install google-generativeai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fatim\\AppData\\Local\\Temp\\ipykernel_22408\\2851657525.py:3: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  import google.generativeai as genai\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Available models for this API key:\n",
            "\n",
            "Model name : models/gemini-2.5-flash\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-pro\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.0-flash\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.0-flash-001\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.0-flash-exp-image-generation\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.0-flash-lite-001\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.0-flash-lite\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-exp-1206\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-preview-tts\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-pro-preview-tts\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3-1b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3-4b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3-12b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3-27b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3n-e4b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemma-3n-e2b-it\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-flash-latest\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-flash-lite-latest\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-pro-latest\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-lite\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-image\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-preview-09-2025\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-lite-preview-09-2025\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-3-pro-preview\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-3-flash-preview\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-3-pro-image-preview\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/nano-banana-pro-preview\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-robotics-er-1.5-preview\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-computer-use-preview-10-2025\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/deep-research-pro-preview-12-2025\n",
            "Supports generateContent: True\n",
            "--------------------------------------------------\n",
            "Model name : models/embedding-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/text-embedding-004\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-embedding-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/aqa\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/imagen-4.0-generate-preview-06-06\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/imagen-4.0-ultra-generate-preview-06-06\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/imagen-4.0-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/imagen-4.0-ultra-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/imagen-4.0-fast-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/veo-2.0-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/veo-3.0-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/veo-3.0-fast-generate-001\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/veo-3.1-generate-preview\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/veo-3.1-fast-generate-preview\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-native-audio-latest\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-native-audio-preview-09-2025\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n",
            "Model name : models/gemini-2.5-flash-native-audio-preview-12-2025\n",
            "Supports generateContent: False\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Load env\n",
        "load_dotenv()\n",
        "\n",
        "API_KEY = os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"No Gemini / Google API key found\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "print(\"ðŸ“‹ Available models for this API key:\\n\")\n",
        "\n",
        "for model in genai.list_models():\n",
        "    print(f\"Model name : {model.name}\")\n",
        "    print(f\"Supports generateContent: {'generateContent' in model.supported_generation_methods}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!ollama run phi3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models import ChatOllama\n",
        "\n",
        "def load_llm1():\n",
        "    return ChatOllama(model=\"phi3\", temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_llm():\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "    load_dotenv()\n",
        "\n",
        "    # LangChain prefers GOOGLE_API_KEY\n",
        "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(\"Please set GOOGLE_API_KEY or GEMINI_API_KEY in .env\")\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-3-flash-preview\",   # âœ… WORKING MODEL\n",
        "        temperature=0,\n",
        "        google_api_key=GOOGLE_API_KEY\n",
        "    )\n",
        "\n",
        "    return llm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def load_llm1():\n",
        "    return ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(profile={}, google_api_key=SecretStr('**********'), model='gemini-3-flash-preview', temperature=0.0, client=<google.genai.client.Client object at 0x000002ACC1197260>, default_metadata=(), model_kwargs={})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_llm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_email_prompt(user_prompt: str):\n",
        "    from langchain_core.prompts import (\n",
        "        ChatPromptTemplate,\n",
        "        SystemMessagePromptTemplate,\n",
        "        HumanMessagePromptTemplate\n",
        "    )\n",
        "    from datetime import datetime\n",
        "\n",
        "    current_date = datetime.today().strftime(\"%A, %B %d, %Y\")\n",
        "\n",
        "    system_text = f\"\"\"\n",
        "You are an AI email intent classification and response agent.\n",
        "Today's date is {current_date}.\n",
        "\n",
        "USER INSTRUCTIONS:\n",
        "{user_prompt}\n",
        "\n",
        "CRITICAL RULES (MUST FOLLOW):\n",
        "1. You MUST respond in STRICT JSON only.\n",
        "2. Do NOT use markdown, explanations, or extra text.\n",
        "3. Grammar mistakes, short emails, or informal language\n",
        "   do NOT mean an email should be ignored.\n",
        "\n",
        "INTENT RULES (VERY IMPORTANT):\n",
        "- If the subject OR body mentions ANY of the following:\n",
        "  meeting, schedule, call, discussion, interview, appointment\n",
        "\n",
        "  â†’ You MUST NOT return \"ignore\".\n",
        "\n",
        "- Emails asking for meetings are ALWAYS genuine.\n",
        "- Promotions, newsletters, and marketing emails\n",
        "  are the ONLY emails you should ignore.\n",
        "\n",
        "ACTION DECISION:\n",
        "- Use \"schedule\" ONLY if date and time are clearly mentioned.\n",
        "- Otherwise use \"reply\" and ask for availability.\n",
        "- If unsure, ALWAYS choose \"reply\".\n",
        "\n",
        "OUTPUT JSON SCHEMA (NO EXCEPTIONS):\n",
        "{{{{ \n",
        "  \"action\": \"reply\" | \"schedule\" | \"ignore\",\n",
        "  \"reply\": \"string\",\n",
        "  \"event\": {{{{\n",
        "    \"title\": \"string\",\n",
        "    \"date\": \"YYYY-MM-DD\",\n",
        "    \"start_time\": \"HH:MM\",\n",
        "    \"end_time\": \"HH:MM\"\n",
        "  }}}}\n",
        "}}}}\n",
        "\n",
        "REPLY STYLE RULES:\n",
        "- Start replies with a short thank-you.\n",
        "- Be polite and professional.\n",
        "\"\"\"\n",
        "\n",
        "    system_msg = SystemMessagePromptTemplate.from_template(system_text)\n",
        "\n",
        "    human_msg = HumanMessagePromptTemplate.from_template(\n",
        "        \"Subject: {subject}\\nFrom: {sender}\\nBody: {body}\"\n",
        "    )\n",
        "\n",
        "    return ChatPromptTemplate.from_messages([system_msg, human_msg])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def fetch_unread_emails(service, max_results=5):\n",
        "    return service.users().messages().list(\n",
        "        userId=\"me\",\n",
        "        labelIds=[\"UNREAD\"],\n",
        "        maxResults=max_results\n",
        "    ).execute().get(\"messages\", [])\n",
        "\n",
        "def extract_email(service, msg_id):\n",
        "    msg = service.users().messages().get(\n",
        "        userId=\"me\",\n",
        "        id=msg_id,\n",
        "        format=\"full\"\n",
        "    ).execute()\n",
        "\n",
        "    headers = msg[\"payload\"][\"headers\"]\n",
        "    subject = sender = \"\"\n",
        "\n",
        "    for h in headers:\n",
        "        if h[\"name\"] == \"Subject\":\n",
        "            subject = h[\"value\"]\n",
        "        elif h[\"name\"] == \"From\":\n",
        "            sender = h[\"value\"]\n",
        "\n",
        "    body = \"\"\n",
        "    payload = msg[\"payload\"]\n",
        "\n",
        "    if \"parts\" in payload:\n",
        "        for part in payload[\"parts\"]:\n",
        "            if part[\"mimeType\"] == \"text/plain\":\n",
        "                data = part[\"body\"].get(\"data\")\n",
        "                if data:\n",
        "                    body = base64.urlsafe_b64decode(data).decode()\n",
        "    else:\n",
        "        data = payload[\"body\"].get(\"data\")\n",
        "        if data:\n",
        "            body = base64.urlsafe_b64decode(data).decode()\n",
        "\n",
        "    return subject, sender, body, msg[\"threadId\"]\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_email_body(body: str) -> str:\n",
        "    # Remove markdown JSON blocks\n",
        "    body = re.sub(r\"```json[\\s\\S]*?```\", \"\", body, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove quoted replies (Gmail style)\n",
        "    body = re.split(r\"\\nOn .* wrote:\", body)[0]\n",
        "\n",
        "    # Remove lines starting with >\n",
        "    body = \"\\n\".join(\n",
        "        line for line in body.splitlines()\n",
        "        if not line.strip().startswith(\">\")\n",
        "    )\n",
        "\n",
        "    return body.strip()\n",
        "\n",
        "def send_reply(service, to, subject, reply, thread_id):\n",
        "    message = MIMEText(reply)\n",
        "    message[\"to\"] = to\n",
        "    message[\"subject\"] = \"Re: \" + subject\n",
        "\n",
        "    raw = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
        "\n",
        "    service.users().messages().send(\n",
        "        userId=\"me\",\n",
        "        body={\"raw\": raw, \"threadId\": thread_id}\n",
        "    ).execute()\n",
        "\n",
        "def mark_read(service, msg_id):\n",
        "    service.users().messages().modify(\n",
        "        userId=\"me\",\n",
        "        id=msg_id,\n",
        "        body={\"removeLabelIds\": [\"UNREAD\"]}\n",
        "    ).execute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def process_all_unread_emails(service, user_prompt, calendar_service=None, max_results=20):\n",
        "    \"\"\"\n",
        "    Process unread emails using AI and take actions (reply, schedule, ignore).\n",
        "    \"\"\"\n",
        "    # Build prompt and LLM\n",
        "    prompt = build_email_prompt(user_prompt)\n",
        "    llm = load_llm()\n",
        "\n",
        "    # Fetch unread emails\n",
        "    emails = fetch_unread_emails(service, max_results=max_results)\n",
        "    print(f\"\\nðŸ“¬ Total unread emails: {len(emails)}\\n\")\n",
        "\n",
        "    if not emails:\n",
        "        print(\"ðŸŽ‰ No unread emails.\")\n",
        "        return\n",
        "\n",
        "    for idx, msg in enumerate(emails, start=1):\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"ðŸ“§ Processing email {idx}/{len(emails)}\")\n",
        "\n",
        "        # Extract email details\n",
        "        subject, sender, body, thread_id = extract_email(service, msg[\"id\"])\n",
        "        body = clean_email_body(body)\n",
        "\n",
        "        print(f\"From   : {sender}\")\n",
        "        print(f\"Subject: {subject}\")\n",
        "        print(\"Body preview:\")\n",
        "        print(body[:300])\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # ---- AI RESPONSE ----\n",
        "        try:\n",
        "            # 1. Invoke the LLM\n",
        "            response_obj = llm.invoke(\n",
        "                prompt.format_prompt(\n",
        "                    subject=subject,\n",
        "                    sender=sender,\n",
        "                    body=body,\n",
        "                    action=\"Reply\"  \n",
        "                ).to_messages()\n",
        "            )\n",
        "            \n",
        "            # 2. FIX: Handle content if it is a list or a string\n",
        "            ai_response = response_obj.content\n",
        "            if isinstance(ai_response, list):\n",
        "                # Extract text if it's a list of parts\n",
        "                ai_response = \"\".join([part['text'] if isinstance(part, dict) else str(part) for part in ai_response])\n",
        "            \n",
        "            # 3. FIX: Clean Markdown formatting if the AI added it\n",
        "            ai_response = ai_response.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ AI invocation failed: {e}. Skipping email.\")\n",
        "            continue\n",
        "\n",
        "        # ---- PARSE JSON ----\n",
        "        try:\n",
        "            result = json.loads(ai_response)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"âŒ AI returned invalid JSON. Skipping email.\")\n",
        "            print(f\"DEBUG: Raw AI Output was: {ai_response}\")\n",
        "            continue\n",
        "\n",
        "        action = result.get(\"action\", \"ignore\")\n",
        "        reply = result.get(\"reply\", \"\")\n",
        "\n",
        "        # ---- Handle scheduled event ----\n",
        "        if action == \"schedule\":\n",
        "            if calendar_service is None:\n",
        "                print(\"âŒ Calendar service not provided. Cannot schedule event.\")\n",
        "                continue\n",
        "\n",
        "            event = result.get(\"event\", {})\n",
        "            start_dt = f\"{event.get('date','')}T{event.get('start_time','00:00')}:00\"\n",
        "            end_dt = f\"{event.get('date','')}T{event.get('end_time','00:00')}:00\"\n",
        "\n",
        "            create_event(\n",
        "                calendar_service,\n",
        "                title=event.get(\"title\", \"Meeting\"),\n",
        "                description=body,\n",
        "                start_dt=start_dt,\n",
        "                end_dt=end_dt\n",
        "            )\n",
        "\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Event scheduled & email marked as read\")\n",
        "            continue\n",
        "\n",
        "        # ---- Handle ignored email ----\n",
        "        if action == \"ignore\":\n",
        "            print(\"ðŸš« AI chose to ignore this email.\")\n",
        "            continue\n",
        "\n",
        "        # ---- Draft reply ----\n",
        "        print(\"\\nðŸ¤– AI Draft Reply\")\n",
        "        print(\"-\" * 50)\n",
        "        print(reply)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        decision = input(\"Send this reply? (y / edit / skip): \").lower()\n",
        "\n",
        "        if decision == \"y\":\n",
        "            send_reply(service, sender, subject, reply, thread_id)\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Reply sent & marked as read\")\n",
        "\n",
        "        elif decision == \"edit\":\n",
        "            edited = input(\"\\nâœï¸ Enter your edited reply:\\n\")\n",
        "            send_reply(service, sender, subject, edited, thread_id)\n",
        "            mark_read(service, msg[\"id\"])\n",
        "            print(\"âœ… Edited reply sent & marked as read\")\n",
        "\n",
        "        else:\n",
        "            print(\"â­ï¸ Skipped (email remains unread)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“¬ Total unread emails: 1\n",
            "\n",
            "======================================================================\n",
            "ðŸ“§ Processing email 1/1\n",
            "From   : fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Project Discussion Meeting\n",
            "Body preview:\n",
            "Hi Saniya,\n",
            "\n",
            "I hope you are doing well. Can we schedule a meeting tomorrow at 3:00 PM\n",
            "IST to discuss the Infosys Email Assistant project progress?\n",
            "Please let me know if that time works for you or suggest another slot.\n",
            "\n",
            "Thanks,\n",
            "Fatimi\n",
            "======================================================================\n",
            "\n",
            "ðŸ¤– AI Draft Reply\n",
            "--------------------------------------------------\n",
            "Yes, tomorrow at 3:00 PM IST works for me. I look forward to discussing the project progress.\n",
            "--------------------------------------------------\n",
            "âœ… Reply sent & marked as read\n"
          ]
        }
      ],
      "source": [
        "USER_PROMPT = \"\"\"\n",
        "Reply only to genuine emails.\n",
        "Ignore promotions and job ads.\n",
        "Be polite, concise, and human-like.\n",
        "Do not add name or signature.\n",
        "\"\"\"\n",
        "\n",
        "process_all_unread_emails(service, USER_PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_state_schema():\n",
        "    from typing import TypedDict, Optional, Dict\n",
        "\n",
        "    class EmailState(TypedDict):\n",
        "        subject: str\n",
        "        sender: str\n",
        "        body: str\n",
        "        thread_id: str\n",
        "        decision: Dict\n",
        "        final_reply: Optional[str]\n",
        "\n",
        "    return EmailState\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ai_decision_node(state, prompt, llm):\n",
        "    import json\n",
        "    import re\n",
        "\n",
        "    # ðŸ” FETCH MEMORY\n",
        "    history = get_sender_history(state[\"sender\"])\n",
        "    memory_text = \"\"\n",
        "\n",
        "    if history:\n",
        "        memory_text = \"\\nPAST INTERACTIONS WITH THIS SENDER:\\n\"\n",
        "        for action, ts in history:\n",
        "            memory_text += f\"- {action} at {ts}\\n\"\n",
        "\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\n",
        "        \"subject\": state[\"subject\"],\n",
        "        \"sender\": state[\"sender\"],\n",
        "        \"body\": state[\"body\"] + memory_text\n",
        "    })\n",
        "\n",
        "    # Normalize content\n",
        "    content = response.content\n",
        "    if isinstance(content, list):\n",
        "        raw = \"\".join(\n",
        "            part if isinstance(part, str) else part.get(\"text\", \"\")\n",
        "            for part in content\n",
        "        )\n",
        "    else:\n",
        "        raw = content\n",
        "\n",
        "    raw = raw.strip()\n",
        "    raw = re.sub(r\"^```json\\s*|```$\", \"\", raw, flags=re.MULTILINE)\n",
        "\n",
        "    try:\n",
        "        decision = json.loads(raw)\n",
        "    except Exception:\n",
        "        decision = {\n",
        "            \"action\": \"reply\",\n",
        "            \"reply\": \"Thank you for your email. Iâ€™ll get back to you shortly.\",\n",
        "            \"event\": {}\n",
        "        }\n",
        "\n",
        "    # safety defaults\n",
        "    decision.setdefault(\"action\", \"reply\")\n",
        "    decision.setdefault(\"reply\", \"\")\n",
        "    decision.setdefault(\"event\", {})\n",
        "\n",
        "    return {\"decision\": decision}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def human_confirmation_node(state):\n",
        "    reply = state[\"decision\"].get(\"reply\")\n",
        "\n",
        "    print(\"\\nðŸ¤– AI Draft Reply\")\n",
        "    print(\"-\" * 60)\n",
        "    print(reply)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Send reply? (y / n / edit): \").strip().lower()\n",
        "\n",
        "        if choice == \"y\":\n",
        "            return {\"final_reply\": reply}\n",
        "\n",
        "        if choice == \"n\":\n",
        "            return {\"final_reply\": None}\n",
        "\n",
        "        if choice == \"edit\":\n",
        "            print(\"\\nâœï¸ Enter edited reply (empty line to finish):\")\n",
        "            lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if not line:\n",
        "                    break\n",
        "                lines.append(line)\n",
        "            return {\"final_reply\": \"\\n\".join(lines)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calendar_node_factory(calendar_service):\n",
        "    def calendar_node(state):\n",
        "        event = state.get(\"decision\", {}).get(\"event\", {})\n",
        "\n",
        "        if not event.get(\"date\") or not event.get(\"start_time\"):\n",
        "            print(\"âš ï¸ Incomplete event data. Skipping calendar.\")\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            start_dt = f\"{event['date']}T{event['start_time']}:00\"\n",
        "            end_dt = f\"{event['date']}T{event.get('end_time', event['start_time'])}:00\"\n",
        "\n",
        "            create_event(\n",
        "                calendar_service,\n",
        "                summary=event.get(\"title\", \"Meeting\"),\n",
        "                description=state.get(\"body\", \"\"),\n",
        "                start=start_dt,\n",
        "                end=end_dt\n",
        "            )\n",
        "\n",
        "            save_email_memory(\n",
        "                sender=state[\"sender\"],\n",
        "                subject=state[\"subject\"],\n",
        "                thread_id=state[\"thread_id\"],\n",
        "                action=\"schedule\"\n",
        "            )\n",
        "\n",
        "            print(\"ðŸ—“ï¸ Event scheduled & remembered\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Calendar Error: {e}\")\n",
        "\n",
        "        return {}\n",
        "\n",
        "    return calendar_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def send_node_factory(service):\n",
        "    def send_node(state):\n",
        "        if state.get(\"final_reply\"):\n",
        "            send_reply(\n",
        "                service,\n",
        "                state[\"sender\"],\n",
        "                state[\"subject\"],\n",
        "                state[\"final_reply\"],\n",
        "                state[\"thread_id\"]\n",
        "            )\n",
        "\n",
        "            # ðŸ’¾ SAVE TO MEMORY\n",
        "            save_email_memory(\n",
        "                sender=state[\"sender\"],\n",
        "                subject=state[\"subject\"],\n",
        "                thread_id=state[\"thread_id\"],\n",
        "                action=\"reply\",\n",
        "                reply=state[\"final_reply\"]\n",
        "            )\n",
        "\n",
        "            print(\"âœ… Reply sent & saved to memory\")\n",
        "        else:\n",
        "            print(\"â­ï¸ Reply skipped\")\n",
        "\n",
        "        return {}\n",
        "\n",
        "    return send_node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_email_graph(user_prompt: str, service, calendar_service):\n",
        "    from langgraph.graph import StateGraph, END\n",
        "\n",
        "    EmailState = get_state_schema()\n",
        "    llm = load_llm()\n",
        "    prompt = build_email_prompt(user_prompt)\n",
        "\n",
        "    graph = StateGraph(EmailState)\n",
        "\n",
        "    graph.add_node(\"ai_decision\", lambda s: ai_decision_node(s, prompt, llm))\n",
        "    graph.add_node(\"human_confirm\", human_confirmation_node)\n",
        "    graph.add_node(\"send\", send_node_factory(service))\n",
        "    graph.add_node(\"calendar\", calendar_node_factory(calendar_service))\n",
        "\n",
        "    graph.set_entry_point(\"ai_decision\")\n",
        "\n",
        "    def router(state):\n",
        "        return state.get(\"decision\", {}).get(\"action\", \"reply\")\n",
        "\n",
        "    graph.add_conditional_edges(\n",
        "        \"ai_decision\",\n",
        "        router,\n",
        "        {\n",
        "            \"reply\": \"human_confirm\",\n",
        "            \"schedule\": \"calendar\",\n",
        "            \"ignore\": END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    graph.add_edge(\"human_confirm\", \"send\")\n",
        "    graph.add_edge(\"send\", END)\n",
        "    graph.add_edge(\"calendar\", END)\n",
        "\n",
        "    return graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_email_assistant(service, calendar_service, user_prompt, max_results=5):\n",
        "    app = build_email_graph(user_prompt, service, calendar_service)\n",
        "    emails = fetch_unread_emails(service, max_results=max_results)\n",
        "\n",
        "    if not emails:\n",
        "        print(\"ðŸ“­ No unread emails found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nðŸ“¬ Total unread emails: {len(emails)}\")\n",
        "\n",
        "    for i, msg in enumerate(emails, start=1):\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"ðŸ“§ Processing email {i}/{len(emails)}\")\n",
        "\n",
        "        subject, sender, body, thread_id = extract_email(service, msg[\"id\"])\n",
        "        body = clean_email_body(body)\n",
        "\n",
        "        print(f\"From   : {sender}\")\n",
        "        print(f\"Subject: {subject}\")\n",
        "        print(\"\\nðŸ“¨ Email Body\")\n",
        "        print(\"-\" * 60)\n",
        "        print(body.strip())\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        state = {\n",
        "            \"subject\": subject,\n",
        "            \"sender\": sender,\n",
        "            \"body\": body,\n",
        "            \"thread_id\": thread_id,\n",
        "            \"decision\": {},\n",
        "            \"final_reply\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            result = app.invoke(state)\n",
        "\n",
        "            if result.get(\"final_reply\") or result.get(\"decision\", {}).get(\"action\") != \"ignore\":\n",
        "                mark_read(service, msg[\"id\"])\n",
        "                print(\"ðŸ“© Email marked as read\")\n",
        "            else:\n",
        "                print(\"â¸ï¸ Email left unread\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Graph failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“¬ Total unread emails: 1\n",
            "\n",
            "======================================================================\n",
            "ðŸ“§ Processing email 1/1\n",
            "From   : fatimi bee <fatimibee312@gmail.com>\n",
            "Subject: Decide the project discussion time.\n",
            "\n",
            "ðŸ“¨ Email Body\n",
            "------------------------------------------------------------\n",
            "Hi Saniya,\n",
            "Please let me know when we discuss the project idea before 5 february 2026.\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸ¤– AI Draft Reply\n",
            "------------------------------------------------------------\n",
            "Thank you for your email. I would be happy to discuss the project idea with you. Please let me know your availability so we can schedule a time before February 5th.\n",
            "------------------------------------------------------------\n",
            "âœ… Reply sent & saved to memory\n",
            "ðŸ“© Email marked as read\n"
          ]
        }
      ],
      "source": [
        "USER_PROMPT = \"\"\"\n",
        "Reply only to genuine emails.\n",
        "Ignore promotions and job ads.\n",
        "Schedule meetings if the email discusses a meeting, call, interview, or appointment.\n",
        "\"\"\"\n",
        "\n",
        "# FIX: Pass BOTH service and calendar_service to the runner\n",
        "run_email_assistant(\n",
        "    service=service, \n",
        "    calendar_service=calendar_service, \n",
        "    user_prompt=USER_PROMPT,\n",
        "    max_results=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('fatimi bee <fatimibee312@gmail.com>', 'reply', 'Thank you for your email. I would be happy to discuss the project idea with you. Please let me know your availability so we can schedule a time before February 5th.', '2026-01-30T12:20:00.915827')\n"
          ]
        }
      ],
      "source": [
        "conn = get_conn()\n",
        "cur = conn.cursor()\n",
        "\n",
        "for row in cur.execute(\"SELECT sender, action,reply, created_at FROM email_memory\"):\n",
        "    print(row)\n",
        "\n",
        "conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
